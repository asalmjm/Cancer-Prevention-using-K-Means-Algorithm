{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import mode\n",
    "from scipy.io import loadmat\n",
    "from sklearn.cluster import KMeans\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    کتابخانه‌های مورد نیاز برای اجرای الگوریتم‌های خوشه‌بندی و ارزیابی عملکرد آنها بارگذاری می‌شوند. این کتابخانه‌ها شامل pandas و numpy برای کار با داده‌ها، sklearn برای استفاده از مدل‌ها و ارزیابی عملکرد آنها، scipy برای استفاده از توابع آماری و بارگذاری دیتاست، و random برای استفاده از توابع مربوط به تولید اعداد تصادفی است.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568, 30)\n",
      "(568, 1)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv(\"breast_data.csv\")\n",
    "print(X.shape)\n",
    "\n",
    "breast_labels = pd.read_csv('breast_labels.csv')\n",
    "print( breast_labels.shape)\n",
    "\n",
    "if breast_labels.shape[0] == X.shape[0]:\n",
    "    y_true = breast_labels \n",
    "else:\n",
    "    print(\"Number of rows in breast_labels does not match the number of rows in X.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    دو مجموعه داده از فایل‌های csv بارگذاری می‌شوند. ابعاد هر یک از مجموعه‌های داده چاپ می‌شود تا مطمئن شویم که بارگذاری درست انجام شده است.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the K-Means Clustering Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanscluster(X, k, mu, tol=1e-4, maxIter=300):\n",
    "    n_samples, n_features = X.shape\n",
    "    C = np.zeros(n_samples, dtype=int)\n",
    "    \n",
    "    for i in range(maxIter):\n",
    "        for j in range(n_samples):\n",
    "            distances = np.linalg.norm(X.iloc[j].values - mu, axis=1)\n",
    "            C[j] = np.argmin(distances)\n",
    "        \n",
    "        mu_old = mu.copy()\n",
    "        for j in range(k):\n",
    "            if np.any(C == j):\n",
    "                mu[j] = X[C == j].mean(axis=0).values\n",
    "        \n",
    "        if np.all(C == np.argmin([np.linalg.norm(X.iloc[j].values - mu, axis=1) for j in range(n_samples)], axis=1)):\n",
    "            break\n",
    "        \n",
    "        if np.linalg.norm(mu - mu_old) < tol:\n",
    "            break\n",
    "            \n",
    "    return C, mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    تابع \"kmeanscluster\"، الگوریتم خوشه‌بندی k-means را برای داده‌های ورودی اجرا می‌کند. ورودی‌های این تابع شامل ماتریس داده‌ها (X)، تعداد خوشه‌های مورد نظر (k)، مقدار اولیه‌های مرکز خوشه‌ها (mu)، مقدار مجاز برای تغییرات کوچک در مراکز خوشه‌ها (tol)، و حداکثر تعداد تکرارهای مجاز (maxIter) است.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1, Accuracy: 0.8538732394366197\n",
      "Run 2, Accuracy: 0.8538732394366197\n",
      "Run 3, Accuracy: 0.8538732394366197\n",
      "Run 4, Accuracy: 0.8538732394366197\n",
      "Run 5, Accuracy: 0.8538732394366197\n",
      "Accuracies for 5 runs with different starting points: [0.8538732394366197, 0.8538732394366197, 0.8538732394366197, 0.8538732394366197, 0.8538732394366197]\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "accuracies = []\n",
    "for i in range(5):   \n",
    "    np.random.seed(i)\n",
    "    initial_centroids = X.sample(n=k, random_state=i).values\n",
    "\n",
    "    C, mu = kmeanscluster(X, k, initial_centroids)\n",
    "\n",
    "    C = C.astype(int)\n",
    "    accuracy1 = accuracy_score(y_true, C)\n",
    "    accuracy2 = accuracy_score(y_true, 1 - C)\n",
    "    \n",
    "    accuracy = max(accuracy1, accuracy2)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Run {i+1}, Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Accuracies for 5 runs with different starting points:\", accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    یک حلقه برای اجرای الگوریتم k-means به صورت تکراری بر روی داده‌های ورودی (X) و برچسب‌های واقعی (y_true) ایجاد شده است. برای هر تکرار، مراکز اولیه برای خوشه‌ها به صورت تصادفی انتخاب می‌شوند. سپس الگوریتم k-means با استفاده از تابع \"kmeanscluster\" اجرا می‌شود. پس از اتمام اجرا، برچسب‌های خوشه‌بندی‌شده (C) از خروجی الگوریتم بدست می‌آید. برای اندازه‌گیری دقت، دو مقدار دقت محاسبه می‌شود: یک مقدار با فرضیه اینکه مقادیر برچسب‌های خوشه‌بندی شده مطابق با برچسب‌های واقعی است و یک مقدار با فرضیه اینکه مقادیر برچسب‌های خوشه‌بندی شده معکوس برچسب‌های واقعی است. در پنج بار اجرای الگوریتم K-Means با نقاط شروع مختلف، ممکن است دقت‌های بدست آمده متفاوت باشند. دقت میانگین به دست آمده نشان‌دهنده کارایی مناسب الگوریتم K-Means در خوشه‌بندی داده‌های سرطان است.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_centroids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering with Provided Initial Centers Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the clustering: 0.8538732394366197\n"
     ]
    }
   ],
   "source": [
    "init_mu = loadmat('init_mu.mat')['mu_init'].T \n",
    "k = init_mu.shape[0]  \n",
    "\n",
    "C, _ = kmeanscluster(X, k, init_mu)\n",
    "\n",
    "C = C.astype(int)\n",
    "accuracy1 = accuracy_score(y_true, C)\n",
    "accuracy2 = accuracy_score(y_true, 1 - C)\n",
    "\n",
    "accuracy = max(accuracy1, accuracy2)\n",
    "print(\"Accuracy of the clustering:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    ماتریس مراکز اولیه برای الگوریتم k-means از یک فایل با پسوند .mat با استفاده از تابع \"loadmat\" خوانده شده و سپس تعداد خوشه‌ها از اندازه این ماتریس مشخص شده و الگوریتم k-means با استفاده از ماتریس مراکز اولیه ورودی اجرا می‌شود.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.6972648853324666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "C, _ = kmeanscluster(X, k, init_mu)\n",
    "C = C.astype(int)\n",
    "\n",
    "silhouette_avg = silhouette_score(X, C)\n",
    "\n",
    "print(\"Silhouette Score:\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "در کلاسترینگ، اغلب از معیارهایی مانند silhouette score استفاده می‌شود زیرا این معیارها اطلاعات بیشتری از ساختار داده‌ها و توزیع خوشه‌ها ارائه می‌دهند نسبت به دقت ساده. اگر میانگین silhouette score برای همه داده‌ها نزدیک به ۱ باشد، نشان می‌دهد که داده‌های هر خوشه بهتر از داده‌های خوشه‌های دیگر با هم مطابقت دارند و خوشه‌بندی مناسبی انجام شده است. در کلاسترینگ، معمولاً دقت به تنهایی معیار مناسبی نیست. زیرا معمولاً در کلاسترینگ، اطلاعات برچسب‌های واقعی موجود نیست و بنابراین نمی‌توان از مقایسه برچسب‌ها برای ارزیابی کیفیت خوشه‌بندی استفاده کرد. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    با استفاده از روش‌های دیگر یادگیری بدون نظارت و همچنین یادگیری با نظارت می‌توان به دقت متفاوتی دست یافت.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Learning Models: k-Means Clustering, Hierarchical Clustering, DBSCAN (Density-Based Spatial Clustering of Applications with Noise), Gaussian Mixture Models (GMM), Principal Component Analysis (PCA), Autoencoders, Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning Models: Linear Regression, Logistic Regression, Decision Trees, Random Forest, Support Vector Machines (SVM), k-Nearest Neighbors (k-NN), Neural Networks, Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Unsupervised Learning Method: DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "\n",
    "dbscan.fit(X)\n",
    "\n",
    "dbscan_labels = dbscan.labels_\n",
    "\n",
    "dbscan_labels_mapped = np.where(dbscan_labels == -1, 2, dbscan_labels)\n",
    "\n",
    "dbscan_accuracy = accuracy_score(y_true, dbscan_labels_mapped)\n",
    "print(\"DBSCAN Accuracy:\", dbscan_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    ابتدا الگوریتم DBSCAN با استفاده از کلاس \"DBSCAN\" از ماژول \"sklearn.cluster\" ایجاد می‌شود. سپس، الگوریتم بر روی داده‌های ورودی (X) اجرا می‌شود و برچسب‌های نهایی برای هر نمونه در متغیر \"dbscan_labels\" ذخیره می‌شوند. مقدار صفر بودن دقت الگوریتم DBSCAN معمولاً نشان‌دهنده عدم توانایی الگوریتم در تشخیص الگوهای خوشه‌بندی مناسب در داده‌ها است. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Supervised Learning Method: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Classifier Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    الگوریتم RandomForestClassifier با 100 درخت تصادفی آموزش داده می‌شود و سپس بر روی داده‌های آزمایشی استفاده می‌شود تا پیش‌بینی انجام دهد. در نهایت، با استفاده از معیار دقت، عملکرد مدل RandomForestClassifier ارزیابی می‌شود و دقت پیش‌بینی چاپ می‌شود.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "    اگر الگوریتم K-Means با مراکز واقعی که پس از خوشه‌بندی واقعی به دست آمده‌اند، مقداردهی اولیه شود، نتایج بهبود می‌یابد. به عبارت دیگر، مشاهده می‌شود که الگوریتم K-Means سریع‌تر به جواب بهینه همگرا می‌شود و خوشه‌بندی دقیق‌تری ارائه می‌شود. دلیل این بهبود، نزدیک بودن مراکز واقعی به خوشه‌های نهایی است. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "   الگوریتم‌های خوشه‌بندی مانند مخلوط‌های گوسی (Gaussian Mixture Models) می‌توانند به نمونه‌هایی که از دو خوشه با پراکندگی متفاوت پیش آمده‌اند، احتمالات نسبت دهند. این الگوریتم می‌تواند خوشه‌هایی با اشکال و اندازه‌های متفاوت را تشخیص دهد که ممکن است K-Means نتواند این کار را به خوبی انجام دهد.\n",
    "\n",
    "از طرف دیگر، اگر برچسب‌های واقعی داده‌ها موجود باشد، می‌توان از روش‌های یادگیری با نظارت مانند کلاسیفیکیشن استفاده کرد. به طور خاص، می‌توان از الگوریتم‌های مانند Support Vector Machines (SVM) یا Random Forests برای دسته‌بندی داده‌های جدید استفاده کرد. این الگوریتم‌ها می‌توانند با استفاده از اطلاعات برچسب‌دار دقت بهتری را به دست آورند.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
